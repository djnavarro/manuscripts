{\rtf1\ansi\deff0\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Times New Roman;}{\f1\froman\fprq2\fcharset0 Times New Roman;}{\f2\froman\fprq2\fcharset0 Times New Roman;}{\f3\froman\fprq2\fcharset0 Palatino Linotype;}{\f4\fnil\fprq0\fcharset0 Tahoma;}{\f5\froman\fprq2\fcharset2 Symbol;}}
{\colortbl;\red0\green0\blue0;\red128\green128\blue128;}
{\stylesheet{\s1\rtlch\afs24\lang255\ltrch\dbch\afs24\langfe1033\loch\fs24\lang1033\snext1 Default;}
{\s2\sa120\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon1\snext2 Text body;}
{\s3\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af4\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon2\snext3 List;}
{\s4\sb120\sa120\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af4\afs20\lang255\ai\ltrch\dbch\af0\afs20\langfe255\ai\loch\f0\fs20\lang1033\i\sbasedon1\snext4 Caption;}
{\s5\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af4\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon1\snext5 Index;}
{\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f0\fs20\lang1033\sbasedon1\snext6 Normal;}
{\s7\cf0\qj{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _26;}
{\s8\li1440\ri0\lin1440\rin0\fi-720\cf0\qj\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _25;}
{\s9\li2160\ri0\lin2160\rin0\fi0\cf0\qj\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _24;}
{\s10\li2880\ri0\lin2880\rin0\fi0\cf0\qj\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _23;}
{\s11\li3600\ri0\lin3600\rin0\fi0\cf0\qj\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _22;}
{\s12\li4320\ri0\lin4320\rin0\fi0\cf0\qj\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _21;}
{\s13\li5040\ri0\lin5040\rin0\fi0\cf0\qj\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _20;}
{\s14\li5760\ri0\lin5760\rin0\fi0\cf0\qj\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _19;}
{\s15\li6480\ri0\lin6480\rin0\fi0\cf0\qj\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _18;}
{\s16\cf0\qj\tx0\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _17;}
{\s17\li1440\ri0\lin1440\rin0\fi-720\cf0\qj\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _16;}
{\s18\li2160\ri0\lin2160\rin0\fi0\cf0\qj\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _15;}
{\s19\li2880\ri0\lin2880\rin0\fi0\cf0\qj\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _14;}
{\s20\li3600\ri0\lin3600\rin0\fi0\cf0\qj\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _13;}
{\s21\li4320\ri0\lin4320\rin0\fi0\cf0\qj\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _12;}
{\s22\li5040\ri0\lin5040\rin0\fi0\cf0\qj\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _11;}
{\s23\li5760\ri0\lin5760\rin0\fi0\cf0\qj\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _10;}
{\s24\li6480\ri0\lin6480\rin0\fi0\cf0\qj\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _9;}
{\s25\cf0\qj\tx0\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _8;}
{\s26\li1440\ri0\lin1440\rin0\fi-720\cf0\qj\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _7;}
{\s27\li2160\ri0\lin2160\rin0\fi0\cf0\qj\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _6;}
{\s28\li2880\ri0\lin2880\rin0\fi0\cf0\qj\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _5;}
{\s29\li3600\ri0\lin3600\rin0\fi0\cf0\qj\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _4;}
{\s30\li4320\ri0\lin4320\rin0\fi0\cf0\qj\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _3;}
{\s31\li5040\ri0\lin5040\rin0\fi0\cf0\qj\tx5040\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _2;}
{\s32\li5760\ri0\lin5760\rin0\fi0\cf0\qj\tx5760\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _1;}
{\s33\li6480\ri0\lin6480\rin0\fi0\cf0\qj\tx6480\tx7200\tx7920{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs24\lang255\ltrch\dbch\af0\afs24\langfe255\loch\f0\fs24\lang1033\sbasedon6\snext6 _;}
{\*\cs35\rtlch\afs24\lang255\ltrch\dbch\afs24\langfe1033\loch\fs24\lang1033 Endnote Characters;}
{\*\cs36\rtlch\afs24\lang255\ltrch\dbch\afs24\langfe1033\loch\fs24\lang1033 Footnote Characters;}
{\*\cs37\rtlch\afs24\lang255\ltrch\dbch\afs24\langfe1033\loch\fs24\lang1033 Numbering Symbols;}
}
{\info{\comment StarWriter}{\vern6450}}\deftab720
{\*\pgdsctbl
{\pgdsc0\pgdscuse195\pgwsxn12240\pghsxn15840\marglsxn1440\margrsxn1440\margtsxn1440\margbsxn1440\pgdscnxt0 Default;}
{\pgdsc1\pgdscuse195\pgwsxn11905\pghsxn16837\marglsxn1134\margrsxn1134\margtsxn1134\margbsxn1134\pgdscnxt1 Endnote;}}
{\*\pgdscno0}\paperh15840\paperw12240\margl1440\margr1440\margt1440\margb1440\sectd\sbknone\pgwsxn12240\pghsxn15840\marglsxn1440\margrsxn1440\margtsxn1440\margbsxn1440\ftnbj\ftnstart1\ftnrstpg\ftnnar\aenddoc\aftnrstcont\aftnstart1\aftnnar
\pard\plain \ltrpar\s6\cf0\qc{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f0\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\qc{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs20\lang255\ab\ltrch\dbch\af0\afs20\langfe255\ab\loch\f3\fs20\lang1033\b {\loch\f3\fs20\lang1033\i0\b Appendix A: The PSP Algorithm}
\par \pard\plain \ltrpar\s6\cf0\qc{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs20\lang255\ab\ltrch\dbch\af0\afs20\langfe255\ab\loch\f3\fs20\lang1033\b 
\par \pard\plain \ltrpar\s6\cf0\qc{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\rtlch\af0\afs20\lang255\ab\ltrch\dbch\af0\afs20\langfe255\ab\loch\f3\fs20\lang1033\b 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The Search Problem}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The PSP search problem can be characterized in the following way. By adopting a particular definition of a data pattern we have induced an unknown finite partition on the parameter space, and our goal is to design a search procedure that visits each elemen
t of the partition at least once. }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The Intuition}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 We adopt a sampling-based search procedure for finding regions. In this kind of procedure we randomly sample parameter values from some distribution, and check to see if they produce a new region. In a na\'efve, ``simple Monte Carlo'' (SMC) approach, we would
 specify a uniform distribution over the whole parameter space. As the number of samples drawn grows arbitrarily large, this procedure will uncover all regions (of non-zero volume) with probability 1. However, in high dimensional spaces this kind of proced
ure is inefficient (as discussed in the main text). As a result, we need to think about more efficient search methods. In essence, this amounts to finding a better probability distribution from which to sample. }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 One of the major inefficiencies in SMC search is that it takes no account of the fact that some regions are much larger than others. The goal in the PSP search is to visit each region at least once, in which case it is inefficient to spend most of one's ti
me in a few big regions. Thus, an ideal sampling distribution would be one that is assigns equally probability to every region in the partition. In short, a natural way to improve on SMC would be to ``rescale'' the space so that all regions ``look the same
 size''. Our PSP algorithm uses a Markov Chain Monte Carlo (MCMC) procedure to attempt this kind of rescaling}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 PSP Sampling by Markov Chain Monte Carlo}
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 MCMC is a powerful method for sampling a complicated {\i target distribution, }denoted {\i f(\u952 ?).} The assumption is that we know how to calculate the value of {\i f(\u952 ?)} , but have no simple method of sampling from it. In the Metropolis-Hastings algorithm, we specify a {\i ju
mping distribution, }denoted {\i q(\u952 ?{{\*\updnprop10000}\dn7 k}|\u952 ?{{\*\updnprop10000}\dn7 k-1}), }used to sample candidate points. With probability {\i a}= {\i f(\u952 ?{{\*\updnprop10000}\dn7 k}) q(\u952 ?{{\*\updnprop10000}\dn7 k}|\u952 ?{{\*\updnprop10000}\dn7 k-1}) / f(\u952 ?{{\*\updnprop10000}\dn7 k-1}) q(\u952 ?{{\*\updnprop10000}\dn7 k-1}|\u952 ?{{\*\updnprop10000}\dn7 k-1}),} the next sampled point is {\i \u952 ?{{\*\updnprop10000}\dn7 k}}. However, with probability 1-{\i a}, we stay in the same spot and the next point is {\i \u952 ?{{\*\updnprop10000}\dn7 k-1}}. Assuming
 that certain regularity conditions are met (discussed later), the values of  {\i \u952 ? }converge to samples from the target distribution.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 Recall that our goal was to specify a target distribution that is uniform over the regions. Obviously it is impossible to specify this distribution directly, since the partition itself is unknown. However, we can specify a series of approximations to this 
ideal distribution that will (under certain regularity conditions, discussed later) eventually converge to it. At any given point in the search, the PSP algorithm will have discovered some number of regions. In order to ensure that each of the discovered r
egions is treated equally, we run a separate Metropolis-Hastings algorithm for each of these regions, each with a target distribution that is uniform on that region (i.e.  {\i f(\u952 ?) {\af\f5 \'b5} 1 {\i0 if }\u952 ? {\i0 belongs to the region, and} {\i f(\u952 ?) }= 0 }{\i0 otherwise). On any given trial, we
 randomly pick one of these chains to draw the next sample from (actually, we systematically sweep through all of them in order to be more efficient, but the principle is the same), thereby ensuring that each of the discovered regions is treated equally ir
respective of size.  }}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 ``Growing'' a Partition}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The procedure outlined above has the rather awkward property of converging to the ideal target distribution (uniform on the regions) so long as the algorithm has already discovered all the regions, which rather defeats the point of the search. In order to 
address this problem, we need to ensure that the algorithm looks outside the discovered regions often enough to ensure that it finds new regions. Our approach to doing this is based on the assumption that the structure of the parameter space varies smoothl
y (formal regularity conditions are discussed later). The idea is, firstly, that new regions will be found near the edges of old regions, and secondly, that the sizes of adjacent regions will be correlated. }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 A natural way to find regions that satisfy these constraints is to adapt the jumping distribution to ensure that the Markov chains jump outside of their region at an ideal rate. To see why this is useful, recall that the target distribution for a given MCM
C routine is uniform on a particular region, so points that lie outside the region will always be rejected. Since we adopt a jumping distribution that is uniform on a small hyper-sphere (again, details to follow), the way to ensure a particular rejection r
ate is to adapt the size of the hyper-sphere. The corollary of this adaptation is that each of the Markov chains will (with some specified rate) jump just outside of its borders, looking for new regions. If the space varies smoothly in the sense discussed 
later, this will be guaranteed to find all the regions.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The other aspect of our approach is that, whenever a new region is encountered, the PSP algorithm concentrates solely on that region until it has ``caught up'' to the pre-existing regions in terms of the number of samples drawn from it (if multiple new reg
ions are found, they are queued until they are all caught up). The reason for this is that the discovery of a new region is essentially a source of information about a potentially informative area of the parameter space that has not yet been fully explored
. Accordingly, since we wish to treat all regions equally, the algorithm concentrates on a new region until it is on an equal footing with all the regions that were previously discovered. By deliberately ensuring that the various chains frequently jump out
side their borders, the PSP algorithm is constantly ``looking'' for new regions.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The Jumping Distribution}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f0\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 As the previous discussion indicates, the choice of jumping distribution is critical to the success of the PSP algorithm. As discussed, we employed a uniform distribution over a hypersphere centered on the current location as the jumping distribution for P
SP. The reason for using a hyper-sphere is that it is widely used in cases where the sampling region is constrained and no prior information is available about the shape of the region; the hyper-spherical shape of a jumping distribution is not likely to fa
vor a particular shape of the sampling domain {\i a priori}.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 In PSP, the size of the jumping distribution ({\i i.e.}, the radius of the hyper-sphere) must adapt to each region. If it is too small, almost all candidate points will be accepted, but every jump will be so small that it will take too many jumps for an exhaust
ive search of a region. Also, rejected points will rarely be generated. In contrast, if the size of the jumping distribution is too large, candidate points will be rejected too often, and the granularity of the jumps will not be small enough to define the 
edges of a region, which requires a properly sized jumping distribution to succeed. Unfortunately, unless one is dealing with a normal distribution, no theory exists that defines the optimal jumping distribution. With the PSP algorithm, we have found it be
st to use an adapt the size of the jumping distribution so that the Markov chain on average accepts 20% to 25 % of the candidate points. In other words, each chain spends 20-25% of its time moving around inside the region, and the rest of its time searchin
g just outside the borders. This range was identified heuristically by testing the algorithm on real and toy models many times using jumping distribution that varied widely in size. }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 This was accomplished by using the standard errors of volume estimates as a criterion of Markov chain efficiency.{\b  {\ul\i [DJN: I don't know what this sentence refers to]}}}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 Formal Description of the PSP Algorithm}
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 We now present a formal description of the PSP algorithm.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f0\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li1095\ri0\lin1095\rin0\fi-1095\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033{\loch\f3\fs20\lang1033\i\b0{\i Step 0. \tab }}{\loch\f3\fs20\lang1033Given {\i \u952 ?{{\*\updnprop10000}\dn7 1 }} and Pattern 1, set {\i m} = {\i i} = 1.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li1095\ri0\lin1095\rin0\fi-1095\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033{\loch\f3\fs20\lang1033\i\b0{\i Step 1.\tab }}{\loch\f3\fs20\lang1033Establish {\i q{{\*\updnprop10000}\dn7 m}(\'b7|\'b7) }by adapting the size of its hyper-spherical domain. Go to step 2.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li1095\ri0\lin1095\rin0\fi-1095\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033{\loch\f3\fs20\lang1033\i\b0{\i Step 2.\tab }}{\loch\f3\fs20\lang1033Set {\i i }= mod({\i i}, {\i m}) + 1. Go to step 3.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li1095\ri0\lin1095\rin0\fi-1095\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033{\loch\f3\fs20\lang1033\i\b0{\i Step 3.\tab }}{\loch\f3\fs20\lang1033Sample {\i \u952 ?{{\*\updnprop10000}\dn7 y}}from {\i q{{\*\updnprop10000}\dn7 i}(\'b7|\u952 ?{{\*\updnprop10000}\dn7 i})}.If {\i \u952 ?{{\*\updnprop10000}\dn7 y} }generates a new valid pattern, set {\i m} = {\i m} + 1, set {\i \u952 ?{{\*\updnprop10000}\dn7 m}}= {\i \u952 ?{{\*\updnprop10000}\dn7 y}}, record the new pattern as Pattern {\i m}, and then go to step 1. If {\i \u952 ?{{\*\updnprop10000}\dn7 y  }}generates Pattern {\i i}, set {\i \u952 ?{{\*\updnprop10000}\dn7 i}}= {\i \u952 ?{{\*\updnprop10000}\dn7 y  }}and go to step 2. Otherwise, go to step 2.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b {\loch\f3\fs20\lang1033\i\b [DJN: This doesn't explain how the adaptation takes place, nor how the new region \ldblquote catches up\rdblquote . Since I don't know exactly what procedure Woojae developed for doing this, I can't fix this myself.] }
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 In the algorithm describe above, {\i q{{\*\updnprop10000}\dn7 i}(\'b7|\u952 ?{{\*\updnprop10000}\dn7 i}) }denotes the jumping distribution of the region corresponding to pattern {\i i}, centered at {\i \u952 ?{{\*\updnprop10000}\dn7 i}}.   The subscript 1 {\u8804 ?} {\i i} {\u8804 ?} {\i m }indexes the region from which we are currently sampling, and {\i m} represents the number of region (o
r number of data patterns) found so far. The algorithm terminates when a preset number of search trials (or size of an MCMC sample) is obtained for {\i each} of the discovered regions. To compensate for the fact that regions discovered early in the search proce
ss are likely to be sampled more than regions discovered later, the algorithm concentrates more on the newly discovered regions in such a way that the total number of trials in the search history will eventually be the same for all regions. An implication 
of this is that the algorithm aggressively searches for new regions in the vicinity of a newly discovered region.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af3\afs20\lang255\ltrch\dbch\af3\afs20\langfe255\loch\f3\fs20\lang1033  
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 Note that the initial conditions (step 0) require an initial parameter set (i.e,  point in parameter space) in order to start the algorithm. These can be provided in one of two ways. Firstly, we could run a preliminary SMC search to find a parameter set th
at yields a valid pattern. Alternatively, if the modeler has a strong intuition about which parameter sets make sense, hey may be able to supply an initial set ``by hand''. In addition to supplying the initial parameter set, these two methods can help the 
PSP algorithm to overcome the potential problem of discontinuity in the partition ({\i i.e.}, disconnected groups of regions), as will be discussed in the next section.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 Regularity Conditions}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 All numerical methods that work in high dimensions require that regularity conditions be satisfied to perform satisfactorily {\b\ul\i [DJN: I've removed the words \ldblquote accurately\rdblquote  and \ldblquote optimally\rdblquote , since as yet, we haven't proved either]}. This is also true of PSP. The f
ollowing six conditions must be met: }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li420\ri0\lin420\rin0\fi-255\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 1. {\i Connectedness}. A data pattern occupies a single connected region in the parameter space, such that any two points that produce the pattern can be joined by a path that passes only through points that produce that same pattern. }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li420\ri0\lin420\rin0\fi-255\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 2. {\i Continuity}. Regions are contiguous with one another in the sense that any two patterns can be joined by a path that passes only through points that produce a valid data pattern.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li420\ri0\lin420\rin0\fi-255\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 3. {\i Smoothness}. The size of the regions changes smoothly in the parameter space, so small regions tend to cluster together}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li420\ri0\lin420\rin0\fi-255\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 4. {\i Stationarity}. Model behavior is stationary in the sense that a given parameter set always generates a single, fixed data pattern. This means that the boundaries of the regions are fixed, not varying every time the model generates a data pattern}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li420\ri0\lin420\rin0\fi-255\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 5. {\i Finite Space}. The volume of the parameter space to be searched is finite.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\li420\ri0\lin420\rin0\fi-255\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 6. {\i Finite Partition}. The partition must be finite,  in that there exist only a finite number of elements to be found.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f0\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b {\loch\f3\fs20\lang1033\i\b [DJN: It should be possible to prove that, given these conditions, the PSP algorithm converges asymptotically to an ergodic Markov chain whose stationary distribution is uniform on the regions, and for each region is uniform on the region. That is, it find
s all regions, and achieves the desired rescaling. Moreover, there's no point in specifying regularity conditions if you don't say what they guarantee (and so far, we haven't done this). In fact, if I were a reviewer, and I saw a whole lot of regularity co
nditions and a few general statements about MCMC, I'd be VERY suspicious].}
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b {\loch\f3\fs20\lang1033\i\b [DJN: Technically, condition 3 is probably unnecessary for this proof, but will probably be needed if we try to show that the rate of convergence is faster than SMC].}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b {\loch\f3\fs20\lang1033\i\b [DJN: I haven't done much with the rest of this section. Just typos and a few minor edits].}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 If these conditions are violated, the PSP algorithm may not work particularly well, so it is useful to ensure that they are met, and to take the appropriate action when they are not. Although some conditions may be self-evident before applying PSP (4, 5), 
others can be more difficult to assess (1, 2, 3, and sometimes 6). In these latter cases, in the absence of proofs to test for violations, the best way to identify and deal with them is through numerical diagnosis using multiple PSP runs. This solution is 
not only common when solving high-dimensional search problems, which is what PSP is doing, but has proven to be successful (e.g., solving the local minima problem in nonlinear optimization). By running the algorithm multiple times with different starting v
alues, tolerance levels, maximum number of function evaluations, etc, one can ascertain whether a consistent solution is obtained. In the same way, the consistency of a PSP solution can be established by performing multiple runs with different starting poi
nts in the parameter space, size of the sample used for an adaptation cycle, and the maximum number of search cycles before termination. Analysis of the resulting data should provide an answer to question. Below we discuss more thoroughly how potential vio
lations of PSP\rquote s regularity conditions can be handled.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The assumptions of continuity and smoothness of  the partitions in the parameter space  are reasonable to make if the computational model being analyzed is composed of mathematical functions that are known to exhibit these properties (i.e., the functions a
re continuous and smooth). If these assumptions are suspected of being violated (e.g., there are breaks in the range of a parameter), the modeler can check the accuracy and consistency of the PSP solution through multiple runs of the algorithm. Estimated c
enter (or mean) points and covariance matrices of discovered regions, which are outputted by the algorithm, will reveal inconsistencies, such as discrepant volume estimates or the number of data patterns found.  Inspection of these values across multiple r
uns should validate any suspicions and reveal the nature of the inconsistency if it exists. In addition, the results of these multiple PSP runs can be combined to create a more accurate picture of model behavior. }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 For example, if one suspects disconnected regions exist in the model, then at least two methods can be used to ensure PSP finds and records both. One is to supply different initial starting points. The modeler, who is most familiar with the behavior of the
 model, may be able to provide parameter values that generate typical patterns as well as less typical patterns that could come from another region in the parameter space. The more sets of parameter values the modeler can provide, the more likely the algor
ithm will find the disconnected regions if they are present. Alternatively, another way to find disconnected regions is to use SMC. That is, randomly sample the parameter space to find these \ldblquote islands.\rdblquote   Large regions are of most importance because the data
 from them could influence the PSP analysis. Fortunately, size works to the modelers advantage in this circumstance because a reasonably long run of SMC should be able to find at least one point in the island, which is all that is needed to discover its ex
istence. The PSP algorithm can take over from there and find the other elements of the partition that belong to the island. In simulation tests in which islands of data patterns were placed in various regions of the parameter space, we have found SMC to wo
rk quite well and in a reasonable amount of time with models that have up to seven dimensions. At higher dimensions, the region becomes such a tiny speck in the model\rquote s parameter space that exponentially longer runs are needed, which can quickly become imp
ractical and the success rate drops.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 This same approach can be used to identify disjoint regions that correspond to the same data pattern. Multiple runs with different initial points or a preliminary SMC run can help detect such discontinuous regions, again, especially if they occupy consider
able individual volumes. Output analysis using estimated center points, volumes, and the covariance matrix of discovered regions will reveal their existence (and location) through discrepancies across repeated measurements.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The stationarity assumption implies that PSP is not applicable to simulation-based, probabilistic models (e.g., distributed connectionist). For this reason, a probabilistic model can be analyzed by PSP only if its simulational component can be replaced wit
h a closed-form probability density (or mass) function, so that data patterns are defined on the space of probability distributions. Study of the application of PSP to probabilistic models is currently underway. As for the requirement that the range of par
ameters must be finite, if some unconstrained parameters are unavoidable (i.e., plausible data patterns could still be generated from their extreme values), it may be useful to reparameterize the model utilizing log, inverse logistic, or other transformati
on function.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 As with some of the preceding assumptions, the finiteness of the partition is not always guaranteed. To promote the successful application of PSP, it is wise to restrict the model\rquote s prediction space by imposing restrictions on possible data patterns when t
hey are reasonable, as was done with ALCOVE {\b\ul\i [DJN: I don't understand this]}. In most cases, such restrictive definition of a data pattern will be justifiable from experimental data or prior work with the model. By precluding nonsensical data patterns, the m
odel analysis can be fair, realistic, and thus informative.}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 \tab }
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 The preceding discussion is intended to alert the potential user to the issues that must be considered when applying PSP. It also serves as demonstration of PSP\rquote s current capabilities. The sampling-based approach to partitioning the parameter space makes i
t a powerful tool for model analysis. There is room for improvement, and enhancements to improve its accuracy and efficiency are being developed. Current and future updates of the algorithm, including Matlab source code and a tutorial, can be found at http
://quantrm2.psy.ohio-state.edu/PSP/}
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ltrch\dbch\af0\afs20\langfe255\loch\f3\fs20\lang1033 {\loch\f3\fs20\lang1033\i0\b0 A Test of the Accuracy of Volume Estimation}
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ltrch\dbch\af0\afs20\langfe255\ai\loch\f3\fs20\lang1033\i 
\par \pard\plain \ltrpar\s6\cf0\ul{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\ql\rtlch\af0\afs20\lang255\ai\ab\ltrch\dbch\af0\afs20\langfe255\ai\ab\loch\f3\fs20\lang1033\i\b {\loch\f3\fs20\lang1033\i\b [DJN: waiting on the new simulations, so I've not written anything about this. However, I do think that it should go after the regularity conditions, since those conditions are conceptually related to the search process, whereas the volume estimation is no
t].}
\par }
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 6.0.7.3 (Linux)"/>
	<meta name="created" content="2019-08-12T21:14:33.207754689"/>
	<meta name="changed" content="2019-08-12T21:18:07.557806808"/>
	<style type="text/css">
		@page { margin: 2cm }
		p { margin-bottom: 0.25cm; line-height: 115% }
		h1 { margin-top: 0.35cm; margin-bottom: 0.11cm; line-height: 100%; text-align: center }
		h1.western { font-family: "Liberation Serif", serif; font-size: 12pt }
		h1.cjk { font-size: 12pt }
		h1.ctl { font-size: 12pt; font-weight: normal }
		h2 { margin-bottom: 0.11cm; line-height: 100%; text-align: left }
		h2.western { font-family: "Liberation Serif", serif; font-size: 11pt }
		h2.cjk { font-family: "Noto Sans CJK SC"; font-size: 11pt }
		h2.ctl { font-family: "Lohit Devanagari"; font-size: 11pt; font-weight: normal }
		h3 { margin-top: 0cm; margin-bottom: 0cm }
		h3.western { font-family: "Liberation Serif", serif; font-size: 12pt }
		h3.cjk { font-family: "Noto Sans CJK SC"; font-size: 10pt }
		h3.ctl { font-family: "Lohit Devanagari"; font-size: 12pt; font-weight: normal }
		a:link { so-language: zxx }
	</style>
</head>
<body lang="en-AU" dir="ltr">
<p lang="en-US" align="center" style="margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<font color="#000000"><font face="Latin Modern Roman"><font size="4" style="font-size: 14pt"><b><font size="3" style="font-size: 12pt">Sampling
frames, Bayesian inference and inductive reasoning</font></b></font></font></font></p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto"><a name="_gjdgxs1"></a>
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Brett
K. Hayes (<a href="mailto:b.hayes@unsw.edu.au">b.hayes@unsw.edu.au</a>)
</span></span></font></span></font></span></font>
</p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Stephanie
Banner (<a href="mailto:steph22banner@gmail.com">steph22banner@gmail.com</a>)
</span></span></font></span></font></span></font>
</p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Danielle
J. Navarro (<a href="mailto:d.navarro@unsw.edu.au">d.navarro@unsw.edu.au</a>)</span></span></font></span></font></span></font></p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">School
of Psychology, University of New South Wales</span></span></font></span></font></span></font></p>
<p align="center" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Sydney,
2052, Australia</span></span></font></span></font></span></font></p>
<p align="center" style="margin-bottom: 0.21cm; line-height: 100%; orphans: 2; widows: 2">
<br/>
<br/>

</p>
<p align="center" style="margin-bottom: 0.21cm; line-height: 100%; orphans: 2; widows: 2">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Abstract</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-right: 0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">We
outline and test a Bayesian model of the effects of evidence sampling
on property induction. Our model assumes that people are sensitive to
the effects of different </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">sampling
frames</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">
applied to sampled evidence. Two studies tested the model by
comparing property generalization following exposure to samples
selected because they belong to the same taxonomic category or
because they share a salient property. Both studies found that
category-based sampling led to broader generalization than
property-based sampling. In line with model predictions, these
differences were attenuated when a mixture of positive and negative
evidence was presented (Experiment 1) and when category-property
relations were probabilistic rather than deterministic (Experiment
2).</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-right: 0.32cm; margin-bottom: 0cm; font-variant: normal; font-style: normal; line-height: 100%; orphans: 2; widows: 2; text-decoration: none">
<br/>

</p>
<p align="justify" style="margin-right: 0.32cm; margin-bottom: 0cm; font-variant: normal; font-style: normal; line-height: 100%; orphans: 2; widows: 2; text-decoration: none">
<br/>

</p>
<p align="left" style="margin-left: 0.33cm; margin-right: 0.33cm; text-indent: -0.33cm; margin-top: 0.21cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><u><span style="background: transparent">Keywords</span></u></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">:
Inductive reasoning; Sampling; Hypothesis testing; Bayesian models;
Categorization</span></span></font></span></font></span></font></p>
<p align="left" style="margin-left: 0.33cm; margin-right: 0.33cm; text-indent: -0.33cm; margin-top: 0.21cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="left" style="margin-right: 0.33cm; margin-top: 0.21cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><u><span style="background: transparent">Citation</span></u></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">:
Hayes, B.K., Banner S. &amp; Navarro, D.J (2017). Sampling frames,
Bayesian inference and inductive reasoning. In G Gunzelmann, A Howes,
T Tenbrink and E Davelaar (Ed.) Proceedings of the 39th Annual
Conference of the Cognitive Science Society</span></span></font></span></font></span></font></p>
<h1 class="western" align="left" style="font-weight: normal"><br/>
<br/>

</h1>
<p style="margin-bottom: 0cm; font-weight: normal; line-height: 100%; page-break-before: always">
<br/>

</p>
<h1 class="western" align="justify"><font face="Latin Modern Roman">Introduction</font></h1>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Inductive
reasoning – the ability to make plausible guesses given
inconclusive evidence – is one of the central topics in cognitive
science. Much of the traditional work on the topic has emphasized the
importance of similarity between premise and conclusion categories
(see Hayes &amp; Heit, 2013, for a review). While undoubtedly useful,
the similarity-based approach overlooks a crucial component of
induction: people’s inductive inferences are strongly influenced by
their beliefs about </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">how</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">
the evidence was sampled (e.g., Xu &amp; Tenenbaum, 2007). This
phenomenon is referred to as </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">sensitivity
to sampling</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
and there is considerable evidence that human reasoners show exactly
this sensitivity.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">One
form of sampling sensitivity occurs when an argument assembled by a
knowledgeable and helpful teacher is evaluated quite differently than
a set of random facts, even if – by chance – the random process
happens to have sampled the same set of facts. In the reasoning
literature, this was first discussed by Medin, Coley, Storms and
Hayes (2003) in their relevance theory of induction. They suggested
that reasoners often make the pragmatic assumption that premise
categories are selected to highlight a salient relation, which is
then used to guide inference. For example, on learning that </font><font size="3" style="font-size: 12pt"><i>zebras</i></font><font size="3" style="font-size: 12pt">
and </font><font size="3" style="font-size: 12pt"><i>skunks</i></font><font size="3" style="font-size: 12pt">
share a novel property, people may infer that the property involves
“having stripes” and generalize accordingly. More recently, the
formal foundations for pragmatic inference have been established
using Bayesian pedagogical sampling models, that model human
inductive reasoning by assuming that helpful teachers select
informative evidence (Voorspoels, Navarro, Perfors, Ransom, &amp;
Storms, 2015; Ransom, Perfors &amp; Navarro, 2016; Shafto &amp;
Bonawitz, 2015). This account is supported by empirical work showing
that many inductive phenomena (e.g., premise non-monotonicity,
integration of positive and negative evidence) depend on the
assumption of a helpful teacher (Ransom et al., 2016; Voorspoels,
Navarro, Perfors, Ransom, &amp; Storms, 2015).</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"> 
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">A
second kind of sensitivity arises from the so-called “strong versus
weak” sampling distinction. Under </font><font size="3" style="font-size: 12pt"><i>strong
sampling</i></font><font size="3" style="font-size: 12pt">, the
learner observes a set of exemplars (e.g., premise categories) that
are constrained to possess property </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">.
Under </font><font size="3" style="font-size: 12pt"><i>weak sampling</i></font><font size="3" style="font-size: 12pt">,
no such constraint exists. Early work highlighted the fact that even
this simple constraint can produce substantial changes to how a
Bayesian reasoner make inferences (Tenenbaum &amp; Griffiths, 2001),
but many applications of the strong/weak distinction have tended to
conflate it with helpful/random sampling (e.g., Xu &amp; Tenenbaum,
2007), and those that do not have found mixed evidence (e.g.,
Navarro, Dry &amp; Lee, 2012). Although there are good reasons to
expect helpfully sampled evidence to be similar to strongly-sampled
evidence (e.g., Ransom et al., 2016), it is not obvious whether (or
when) people are sensitive to sampling assumptions if no helpful
teacher is available. Perhaps people are capable of taking a hint
from a helpful teacher, but otherwise are largely insensitive to
sampling assumptions. Given other evidence that people struggle with
conditional probability (e.g, Fiedler, 2012) this is not an
implausible idea.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<h2 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">How
sampling frames shape induction</font></font></h2>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">In
this paper, we approach the problem from a different perspective, and
consider other ways in which data can be sampled in a constrained
way. The statistics literature, for instance, emphasizes the
importance of a </font><font size="3" style="font-size: 12pt"><i>sampling
frame</i></font><font size="3" style="font-size: 12pt"> (Jessen,
1978): when designing a survey, the researcher may not be able to
sample uniformly at random from the entire population of interest,
but is instead forced to sample from a restricted subset. When
interpreting such data, those properties of the observed data that
are attributable to the sampling frame do not require theoretical
explanation, as they are deemed an artifact of the sampling process. </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">The
effect of a sampling frame can be substantial. Imagine that you want
to learn what plants make you sneeze. The potential search space is
large so we apply a sampling frame – we first test a particular
category of plant (e.g., sunflowers) – and find that most
sunflowers cause us to sneeze. In this situation, the fact that we
have never sneezed at a daisy is irrelevant: it can be attributed to
the sampling frame. In this context, absence of evidence is not
evidence of absence. </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Now
consider the effect of shifting the sampling frame. Suppose instances
are selected </font><font size="3" style="font-size: 12pt"><i>because</i></font><font size="3" style="font-size: 12pt">
they share the property of interest (e.g., they give positive result
on an allergy test). If most of </font><font size="3" style="font-size: 12pt"><i>this</i></font><font size="3" style="font-size: 12pt">
sample was sunflowers then the absence of daisies might be seen as
inductively informative: it suggests that the allergic reaction is
limited to the observed category. Despite the fact that neither
scenario involves a helpful teacher, the mere presence of a sampling
frame allows the same data to lead to different generalizations (cf.
Hsu, Horng, Griffiths, &amp; Chater, 2016).</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">There
is evidence that people are sensitive to the sampling frame. Lawson
and Kalish (2009) presented participants with samples of animals
(small birds) that shared a novel property (“</font><font size="3" style="font-size: 12pt"><i>has
plaxium blood</i></font><font size="3" style="font-size: 12pt">”)
and manipulated the way exemplars were sampled. In the “category
sampling” condition they were told that items were sampled from a
taxonomic category (i.e., the frame selects small birds). In the
“property sampling” condition people were told that exemplars
with plaxium blood were selected. People in the property sampling
condition were less likely to generalize the property to other
animals. Lawson and Kalish (2009) noted that this result was
inconsistent with similarity-based accounts of induction, but they
did not explain why the differences occurred.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">As
it happens, this pattern of results is exactly what one would expect
from a probabilistic reasoner who is sensitive to the sampling frame.
Later we present a formal model, but the qualitative intuition is
simple. Suppose the learner has observed small birds (</font><font size="3" style="font-size: 12pt"><i>S</i></font><font size="3" style="font-size: 12pt">)
with plaxium blood (</font><font size="3" style="font-size: 12pt"><i>P+</i></font><font size="3" style="font-size: 12pt">),
and is trying to determine whether large birds (</font><font size="3" style="font-size: 12pt"><i>L</i></font><font size="3" style="font-size: 12pt">)
also possess plaxium blood. Subject to the constraint that large and
small birds both exist, there are six hypotheses consistent with the
observations, as shown in Figure 1, and three that are not. </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Now
consider the plausibility of these six hypotheses under different
sampling frames, illustrated by the red rectangles in Figures 2. In
category sampling, it is plausible to assume that if any small birds
did not have plaxium blood, the </font><font size="3" style="font-size: 12pt"><i>SP-</i></font><font size="3" style="font-size: 12pt">
case would have been observed. The lack of such observations
strengthens three hypotheses and weakens three others. Notably, two
remaining hypotheses allow large birds to have plaxium blood (</font><font size="3" style="font-size: 12pt"><i>LP+</i></font><font size="3" style="font-size: 12pt">).
By contrast, in property sampling it is reasonable to assume that if
any large birds had plaxium blood we should have seen the </font><font size="3" style="font-size: 12pt"><i>LP+</i></font><font size="3" style="font-size: 12pt">
case. The fact that they were not leaves only two viable hypotheses,
both of which restrict property </font><font size="3" style="font-size: 12pt"><i>P</i></font><font size="3" style="font-size: 12pt">
to the target category. Accordingly, generalization is more
restricted under property sampling.</font></font></p>
<h1 class="western" align="justify" style="orphans: 0; widows: 0"><font face="Latin Modern Roman">Experiment
1</font></h1>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; orphans: 0; widows: 0">
<br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Our
experimental work replicates the findings of Lawson and Kalish
(2009), and extends them in a way that tests our “sampling frames”
explanation. In the first experiment, we considered the impact of
explicit negative evidence. If a learner encounters non-target
category members that lack property </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">P</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
the differences between the two sampling conditions should attenuate.
Explicit negative evidence should have a large effect in the category
sampling condition, but only a modest effect under property sampling.
We expect this difference because property sampling already provides
implicit negative evidence, so the added value of the explicit
negative evidence is diminished</span></span></font></span></font></span><font size="3" style="font-size: 12pt">.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Experiment
1 tested these predictions by presenting participants with identical
evidence samples obtained via category or property sampling. Half the
participants received positive evidence about members of a target
category, as per Lawson and Kalish (2009), and half received
additional negative evidence about non-target category members. All
participants were then asked to judge whether the novel property
generalized to other categories.</font></font></p>
<h2 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">Method</span></i></font></font></h2>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<h3 class="western" align="justify" style="page-break-after: auto"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><u><span style="font-weight: normal">Participants</span></u></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">.
92 UNSW students (63 female), participated for course credit or
payment. The mean age was 20.9 years.</span></font></font></h3>
<h3 class="western" align="justify" style="font-weight: normal"><br/>

</h3>
<h3 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><u><span style="font-weight: normal">Design
and Procedure</span></u></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">.
The experiment used a 2 x 2 between subjects design with equal
numbers in each condition. The procedure for the </span></font><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">positive
evidence only</span></i></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">
groups was patterned after Lawson and Kalish (2009). Participants
were told they were investigating the properties of animals on a
novel island. In the </span></font><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">category
sampling</span></i></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">
condition, participants were told that only small birds were sampled
from the island. In the </span></font><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">property
sampling</span></i></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">
conditions, they were told that only animals with plaxium blood were
sampled from the island. Exemplars were revealed as follows: on each
of 20 trials, participants could click on one of a large number of
on-screen boxes to see an exemplar (each depicted by a unique picture
of a small bird), and to learn if the animal had plaxium blood. In
the positive evidence condition, all 20 exemplars sampled had plaxium
blood.</span></font></font></h3>
<h3 class="western" align="justify"> 
</h3>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">For
the </font><font size="3" style="font-size: 12pt"><i>positive+negative
evidence</i></font><font size="3" style="font-size: 12pt"> groups the
procedure was identical, except that there were five trials at the
end in which “new” samples from the island were presented. Each
of these revealed a single instance from other animal categories
(crow, seagull, eagle, squirrel, frog) that did not have plaxium
blood. These five trials were always presented, in random order, at
the end of sampling phase.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">After
the learning phase, all participants proceeded to a generalization
test. On each of six trials, participants were shown a picture of an
animal and asked to estimate the number of such animals from a sample
of ten that would have plaxium blood (0-10). The test categories
included a member of the same target category that was presented
during sampling (a novel picture of a sparrow) and five categories
that varied in similarity to the target (pigeon, owl, ostrich, mouse,
lizard). Test item order was randomized.</font></font></p>
<h2 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">Results
and Discussion</span></i></font></font></h2>
<p align="justify" style="margin-bottom: 0cm; font-weight: normal; line-height: 100%">
<br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Generalization
scores (out of 10) for all conditions are shown in Figure 3. Visual
inspection suggests that the positive-only condition people
generalized more narrowly under property sampling (black squares)
than under category sampling (black circles). Moreover, this
difference is less pronounced when explicit negative evidence is
provided (in grey)</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">.
</font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">More
formally, a mixed effects ANOVA revealed that people were less
willing to generalize as similarity decreased (left to right in
Figure 3; linear trend contrast: </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,84)
= 420.07, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">&lt;.001).
Generalization to non-target categories was greater following
category than property sampling, </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,84)
= 12.36, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">
=.001, and when only positive evidence was encountered during
sampling, </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,84)
= 39.54, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">&lt;.001.
The critical finding, however is the interaction:  the </font><font size="3" style="font-size: 12pt"><i>difference</i></font><font size="3" style="font-size: 12pt">
in generalization between category and property sampling was larger
in the positive evidence only condition than in the positive +
negative condition, </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,84)
= 5.81, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">
=.02.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">These
results are exactly what we expected: despite the fact that
participants in the category and property sampling groups saw exactly
the same information, generalization of the novel property was
narrower following property sampling. This replicates the main
finding of Lawson and Kalish (2009), showing that people’s
inductive inferences are sensitive to the sampling frame. Moreover,
the data supported a novel prediction of our sampling explanation:
presentation of negative evidence had greater impact on
generalization following category sampling than property sampling. </font></font>
</p>
<h1 class="western" align="justify"><br/>
<br/>

</h1>
<h1 class="western" align="justify"><font face="Latin Modern Roman">Experiment
2</font></h1>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">In
the next experiment we consider a second manipulation that should –
according to the sampling account – attenuate the difference
between category and property sampling: ambiguous evidence. In
Experiment 1, every member of the target category had the novel
property. In Experiment 2, we considered cases where some of the
evidence is ambiguous, by including some observations where the
plaxium status of the entity was unknown. The qualitative intuition
here is that this should introduce uncertainty about the distribution
of the property within the target category. Accordingly, the
evidentiary value of the data should decrease, leading to a less
pronounced difference between the two sampling conditions.</span></span></font></span></font></span></font></p>
<h2 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">Method</span></i></font></font></h2>
<h3 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><u><span style="font-weight: normal">Participants</span></u></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">.
80 UNSW students (76 female), participated for course credit or
payment. The mean age was 19.4 years. </span></font></font>
</h3>
<h3 class="western" align="justify"><br/>

</h3>
<h3 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><u><span style="font-weight: normal">Design
&amp; Procedure</span></u></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">.
The experiment used a 2 x 2 between subjects design, with equal
numbers in each condition. The procedure for the </span></font><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">deterministic
evidence</span></i></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">
conditions was identical to the positive evidence only conditions in
Experiment 1. The procedure for the </span></font><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">probabilistic
evidence</span></i></font><font size="3" style="font-size: 12pt"><span style="font-weight: normal">
conditions was similar, except that during the sampling phase
participants saw an additional five category or property sampling
trials. On these trials, additional small birds were presented whose
blood type was unknown due to a “machine error”. These trials
were randomly interspersed with the other trials. The generalization
test was the same as Experiment 1.</span></font></font></h3>
<h2 class="western" align="justify"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><i><span style="font-weight: normal">Results
and Discussion</span></i></font></font></h2>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Generalization
scores are shown in Figure 4. As in Experiment 1, generalization of
the novel property decreased as similarity to the target category
decreased (linear trend contrast: </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,76)
= 117.94, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">&lt;.001.
Overall, generalization to non-target categories was greater
following category than property sampling, </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,76)
= 8.88, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">=.004.
Notably, there was a significant interaction between sampling
condition and evidence certainty, </font><font size="3" style="font-size: 12pt"><i>F</i></font><font size="3" style="font-size: 12pt">(1,76)
= 5.25, </font><font size="3" style="font-size: 12pt"><i>p</i></font><font size="3" style="font-size: 12pt">
=.03. Figure 4 shows that the differences in generalization between
category and property sampling were relatively large when the
evidence was deterministic, but decreased when the observed evidence
was probabilistic. </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">The
results for the deterministic evidence condition replicate the
earlier finding that property sampling leads to narrower
generalization than category sampling. Consistent with the
predictions of our model, the difference between sampling conditions
was reduced when the relationship between the target property and
category was probabilistic. </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-top: 0.35cm; margin-bottom: 0.11cm; line-height: 100%">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><b>Bayesian
reasoning with sampling frames</b></font></font></p>
<p align="justify" style="margin-top: 0.35cm; margin-bottom: 0.11cm; line-height: 100%">
<br/>
<br/>

</p>
<p align="justify" style="margin-top: 0.11cm; margin-bottom: 0cm; line-height: 100%">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">The
sampling explanation outlined at the start of the paper provides an
intuitive explanation of our results: in this section we provide a
more formal account, introducing an inductive reasoning model that
accommodates the effect of the sampling frame within the Bayesian
framework introduced by Tenenbaum and Griffiths (2001).</font></font></p>
<p align="justify" style="margin-top: 0.11cm; margin-bottom: 0cm; line-height: 100%">
<br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">A
Bayesian analysis of the inductive problem proceeds as follows. The
test categories consist of items that belong to different taxonomic
classes (</font><font size="3" style="font-size: 12pt"><i>birds</i></font><font size="3" style="font-size: 12pt">,
</font><font size="3" style="font-size: 12pt"><i>mammals</i></font><font size="3" style="font-size: 12pt">,
</font><font size="3" style="font-size: 12pt"><i>reptiles</i></font><font size="3" style="font-size: 12pt">)
and vary in size (</font><font size="3" style="font-size: 12pt"><i>small</i></font><font size="3" style="font-size: 12pt">,
</font><font size="3" style="font-size: 12pt"><i>medium</i></font><font size="3" style="font-size: 12pt">,
</font><font size="3" style="font-size: 12pt"><i>large</i></font><font size="3" style="font-size: 12pt">,
and </font><font size="3" style="font-size: 12pt"><i>huge</i></font><font size="3" style="font-size: 12pt">).
Given this, we define a hypothesis space </font><font size="3" style="font-size: 12pt"><span style="font-style: normal"><b>H</b></span></font><font size="3" style="font-size: 12pt">
by combining these two characteristics. A hypothesis </font><font size="3" style="font-size: 12pt"><i>h
</i></font><font size="3" style="font-size: 12pt">is admissible if it
includes only a single taxonomic class (e.g., </font><font size="3" style="font-size: 12pt"><i>birds
only</i></font><font size="3" style="font-size: 12pt">) or allows </font><font size="3" style="font-size: 12pt"><i>all</i></font><font size="3" style="font-size: 12pt">
animals to possess plaxium. Similarly, it is admissible if it
specifies a “connected” region on the size dimension (e.g.,
</font><font size="3" style="font-size: 12pt"><i>small-or-medium</i></font><font size="3" style="font-size: 12pt">
is allowed, but </font><font size="3" style="font-size: 12pt"><i>small-or-huge</i></font><font size="3" style="font-size: 12pt">
is not). For simplicity, the Bayesian model assigns equal prior
probability </font><font size="3" style="font-size: 12pt"><i>P(h)</i></font><font size="3" style="font-size: 12pt">
to all hypotheses, with one exception: to account for the fact that
people are less willing to generalize across taxonomic classes than
across animal sizes, hypotheses that allows </font><font size="3" style="font-size: 12pt"><i>all</i></font><font size="3" style="font-size: 12pt">
animals to have plaxium blood are only 1/5 as plausible as hypotheses
restricted to a single class. </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">When
presented with a set of observations </font><font size="3" style="font-size: 12pt"><i>x</i></font><font size="3" style="font-size: 12pt">,
the learner updates the prior distribution to a posterior via Bayes’
rule: </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%">    
       
<img src="2017_framescogsci_html_5cae9e3ffde9e734.png" name="image2.png" align="bottom" width="213" height="34" border="0"/>

     
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"> 
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">In
this expression, the likelihood term </font><font size="3" style="font-size: 12pt"><i>P(x|h,f)</i></font><font size="3" style="font-size: 12pt">
describes the probability of observing the data </font><font size="3" style="font-size: 12pt"><i>x</i></font><font size="3" style="font-size: 12pt">
if hypothesis </font><font size="3" style="font-size: 12pt"><i>h</i></font><font size="3" style="font-size: 12pt">
is true and the sampling frame </font><font size="3" style="font-size: 12pt"><i>f</i></font><font size="3" style="font-size: 12pt">
applies. When determining the probability that a test item </font><font size="3" style="font-size: 12pt"><i>y
</i></font><font size="3" style="font-size: 12pt">possesses plaxium
blood, a Bayesian learner aggregates the posterior probability
assigned to those hypotheses </font><font size="3" style="font-size: 12pt"><i>h</i></font><font size="3" style="font-size: 12pt">
that assign the test item y to the consequential set:</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%">    
             
<img src="2017_framescogsci_html_e93aad311399c2b3.png" name="image1.png" align="bottom" width="185" height="34" border="0"/>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">The
critical feature of this model is the fact that the likelihood term
</font><font size="3" style="font-size: 12pt"><i>P(x|h,f)</i></font><font size="3" style="font-size: 12pt">
is sensitive to the sampling frame. Under category sampling, the fact
that all observations happen to be small birds is of no evidentiary
value: the sampling frame </font><font size="3" style="font-size: 12pt"><i>f</i></font><font size="3" style="font-size: 12pt">
only admits small birds, and no explanation for this is required. In
this sampling regime, a good hypothesis is required to explain the
fact that all observations are plaxium positive. If we assume a noisy
relationship, where </font><font size="3" style="font-size: 12pt"><i>θ
</i></font><font size="3" style="font-size: 12pt">&gt;.5 denotes the
probability that an animal that falls within the relevant category
possesses plaxium blood, then the likelihood becomes:</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">		</font><img src="2017_framescogsci_html_2f0cdddb27b7b125.png" name="image3.png" align="bottom" width="197" height="33" border="0"/>
</font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Under
property sampling, this pattern is reversed: the sampling frame
admits only plaxium positive observations, and no explanation for
this is required. Instead, the data </font><font size="3" style="font-size: 12pt"><i>x</i></font><font size="3" style="font-size: 12pt">
that the learner must explain is the fact that all the animals are
small birds. Again assuming a noisy relationship, </font></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">		</font><img src="2017_framescogsci_html_287cb6a12a8fa863.png" name="image5.png" align="bottom" width="215" height="32" border="0"/>
</font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">In
this expression, the normalizing term |h| denotes the “size” of
the hypothesis. For a hypothesis that predicts </font><font size="3" style="font-size: 12pt"><i>m</i></font><font size="3" style="font-size: 12pt">
species to be plaxium positive and </font><font size="3" style="font-size: 12pt"><i>n</i></font><font size="3" style="font-size: 12pt">
species to be plaxium negative,</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%">    
              
<img src="2017_framescogsci_html_89e5c1f5a0ee8179.png" name="image4.png" width="111" height="14" border="0"/>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Formal
details notwithstanding, the main point of these equations is to
highlight the fact that the different sampling frames involved
ensures that property sampling imposes a </font><font size="3" style="font-size: 12pt"><i>size
principle</i></font><font size="3" style="font-size: 12pt">
(Tenenbaum &amp; Griffiths 2001) and category sampling does not. When
a size principle applies, Bayesian learners will tend to assign more
belief to smaller hypotheses, and as a consequence will generalize
narrowly. This is illustrated in the top panel of Figure 5 which
plots the generalizations made by the Bayesian model when presented
with 20 plaxium positive small birds, setting </font><font size="3" style="font-size: 12pt"><i>θ
</i></font><font size="3" style="font-size: 12pt">= 0.6. As one might
expect, the Bayesian model generalizes more narrowly under property
sampling.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">In
Experiment 1, we found that the difference between the two sampling
schemes attenuated when participants were presented with plaxium
negative observations from non-target categories, and generalizations
narrowed in general. As shown in the middle panel of Figure 5, this
is exactly what the Bayesian model does. Regardless of sampling
scheme, the negative evidence serves to decrease the plausibility of
larger hypotheses (as they are now somewhat inconsistent with the new
data), but this has a much smaller effect in the property sampling
condition simply by virtue of the fact that these hypotheses were
already judged to be somewhat implausible. Accordingly, the Bayesian
model produces narrower generalizations and the difference between
the two conditions becomes smaller.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">In
Experiment 2, participants were presented with additional “ambiguous”
observations (small birds that may or may not have been plaxium
positive). This manipulation is expected to cause people to suspect a
noisier relationship between the category and the observed plaxium
status, which we operationalize by setting a lower value for </font><font size="3" style="font-size: 12pt"><i>θ.</i></font><font size="3" style="font-size: 12pt">
When we set </font><font size="3" style="font-size: 12pt"><i>θ </i></font><font size="3" style="font-size: 12pt">=
.55, we obtain the generalization gradients shown in the right panel
of Figure 5. As expected, the Bayesian model produces an attenuated
effect of sampling. </font></font>
</p>
<p align="justify" style="line-height: 100%"><br/>
<br/>

</p>
<p align="justify" style="margin-top: 0.25cm; margin-bottom: 0.11cm; line-height: 100%">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt"><b>General
Discussion</b></font></font></p>
<p align="justify" style="margin-top: 0.25cm; margin-bottom: 0.11cm; line-height: 100%">
<br/>
<br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Traditionally,
models of property induction (e.g., Osherson et al., 1990) have
focused on the similarity between the categories known to possess a
property and other categories to which the property might be
generalized. Although category similarity is undoubtedly an important
component of induction, the current work highlights the additional
impact of beliefs about how observed data is sampled. In both
experiments, identical sets of observations led to very different
patterns of generalization depending on beliefs about how the
observations were selected. In the positive evidence condition in
Experiment 1 and the corresponding deterministic condition in
Experiment 2, evidence sampling based on shared category membership
led to broader generalization of the target property than evidence
sampling based on a shared property. </span></span></font></span></font></span></font>
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">This
result shows that people are sensitive to the effects of particular
constraints or sampling frames that are imposed on the observations.
In category-based sampling, the absence of observations of members of
other categories that share a target property is not necessarily seen
as evidence of absence. In property-based sampling, the absence of
such observations can be seen as evidence that the property does not
project beyond the target category. This phenomenon is naturally
accommodated by a Bayesian inductive reasoning model. Moreover, this
theoretical perspective allowed us to generate two novel predictions.
The effect of sampling frame attenuates when explicit negative
evidence is added or when ambiguity is introduced to the sample. Both
of these effects are captured by the Bayesian model.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Our
Bayesian approach suggests additional factors that should moderate
the impact of sampling frames. For example, differences in
generalization patterns between types of sampling is likely to depend
on beliefs about category base rates. In property sampling for
example, if members of both the target category (e.g., small birds)
and non-target categories (e.g., various types of large birds) are
believed to be relatively common, then the fact that the sample of
animals with plaxium blood contains no large birds is highly
informative. In contrast, if large birds were uncommon, then the
absence of large birds with plaxium blood does not license strong
conclusions about property generalization.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"> 
</p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Previous
work (Ransom et al., 2015; Shafto &amp; Bonawitz, 2015) has shown
that inductive inferences are sensitive to </font><font size="3" style="font-size: 12pt"><i>intentional</i></font><font size="3" style="font-size: 12pt">
factors associated with sample selection (e.g., whether the
observations were chosen by a helpful agent to illustrate the breadth
of a hypothesis). The current work, together with that of Lawson and
Kalish (2009), highlights the importance of a novel factor in
induction, namely sensitivity to different types of
</font><font size="3" style="font-size: 12pt"><i>conditionalization</i></font><font size="3" style="font-size: 12pt">
or filtering of the evidence samples on which inferences are based.
While this is a new finding in the domain of induction, it bears some
resemblance to results observed in probability judgment tasks (see
Fielder, 2012 for a review). Fiedler, Brinkman, Betsch and Wild
(2000) for example, presented different groups with different types
of conditionalized samples. One group saw instances of women who had
received a positive breast scan result, and learned whether each
woman had breast cancer. Another group saw instances of women with
breast cancer and learned whether they had received a positive breast
scan. As in the current work, people were sensitive to these
different types of sample conditionalization, with the two groups
generating very different estimates of the probability that a woman
with a positive scan had cancer. In the Fiedler, et al. (2000) study
however, the different types of conditionalization led to differences
in the characteristics of the instances observed in each sample. The
current work goes further, by showing that very different patterns of
inference emerge when identical evidence samples are selected via
different types of sampling frames.</font></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%"><br/>

</p>
<h1 class="western" align="justify" style="margin-top: 0.39cm; line-height: 100%">
<font face="Latin Modern Roman">Acknowledgments</font></h1>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">This
work was supported by Australian Research Council Discovery Grant
DP150101094 to the first author. We thank Jeremy Ngo and Minoli
Jinasena for assistance in running the experiments.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<h1 class="western" align="justify" style="margin-top: 0.39cm; line-height: 100%">
<font face="Latin Modern Roman">References<span style="font-weight: normal">
</span></font>
</h1>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Fiedler,
K., Brinkmann, B., Betsch, T., &amp; Wild, B. (2000). A sampling
approach to biases in conditional probability judgments: Beyond base
rate neglect and statistical format. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Journal
of Experimental Psychology: General</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">129</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
399-418. </span></span></font></span></font></span></font>
</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Fiedler,
K. (2012). Meta-cognitive myopia and the dilemmas of
inductive-statistical inference. In B. H. Ross (Ed.), </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">The</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Psychology
of Learning and Motivation</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">
(Volume 57, pp. 1-55). Cambridge, MA: Academic Press</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Hayes,
B. K., &amp; Heit, E. (2013). Induction. In D. Reisberg (Ed.) </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Oxford
Handbook of Cognitive Psychology</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">.
Oxford University Press, New York, USA.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Hsu,
A. S., Horng, A., Griffiths, T. L., &amp; Chater, N. (2016), When
absence of evidence is evidence of absence: Rational inferences from
absent data. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Cognitive
Science</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
1-13.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Jessen,
R. J. (1978). </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Statistical
survey techniques</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">.
New York: Wiley.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Lawson,
C. &amp; Kalish, C. (2009). Sample selection and inductive
generalization. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Memory
&amp; Cognition</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">37</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
596-607. </span></span></font></span></font></span></font>
</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Medin,
D., Coley, J., Storms, G., &amp; Hayes, B. (2003). A relevance theory
of induction. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Psychonomic
Bulletin &amp; Review</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">10</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
517-532.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Navarro,
D., Dry, M. &amp; Lee, M. (2012).  Sampling assumptions in inductive
generalization. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Cognitive
Science</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">36</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">(2),
187-223.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Osherson,
D., Smith, E., Wilkie, O., López, A., &amp; Shafir, E. (1990).
Category-based induction. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Psychological
Review</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">97</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
185-200.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Ransom,
K., Perfors, A., &amp; Navarro, D. (2016). Leaping to conclusions:
Why premise relevance affects argument strength. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Cognitive
Science</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">40</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
1775-1796.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Shafto,
P., &amp; Bonawitz, E. (2015). Choice from intentionally selected
options. In B. H. Ross (Ed.). The </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Psychology
of Learning and Motivation</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">
(Volume 63, pp. 115-139). Cambridge, MA: Academic Press</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Tenenbaum
J. &amp; Griffiths T. (2001). Generalization, similarity and Bayesian
inference. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Behavior
&amp; Brain Sciences, 24</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
629-640.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Voorspoels,
W., Navarro, D., Perfors, A., Ransom, K., &amp; Storms, G. (2015).
How do people learn from negative evidence? Non-monotonic
generalizations and sampling assumptions in inductive reasoning.
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Cognitive
Psychology</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">81</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
1-25.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<font face="Latin Modern Roman"><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">Xu,
F., &amp; Tenenbaum, J. (2007). Sensitivity to sampling in Bayesian
word learning. </span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">Developmental
Science</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
</span></span></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><i><span style="background: transparent">10</span></i></font></span></font></span><span style="font-variant: normal"><font color="#000000"><span style="text-decoration: none"><font size="3" style="font-size: 12pt"><span style="font-style: normal"><span style="background: transparent">,
288-297.</span></span></font></span></font></span></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; page-break-inside: auto; orphans: 2; widows: 2; page-break-after: auto">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2; page-break-before: always">
<br/>

</p>
<p align="justify" style="margin-top: 0.39cm; margin-bottom: 0.11cm; line-height: 100%; orphans: 2; widows: 2">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Figure
1:</font></font></p>
<p align="justify" style="margin-top: 0.39cm; margin-bottom: 0.11cm; line-height: 100%; orphans: 2; widows: 2">
<img src="2017_framescogsci_html_2d1177cc80ce1206.png" name="Image1" align="left" width="356" height="414">
  <br clear="left"/>
</img>
<br/>
<br/>

</p>
<p align="justify" style="margin-top: 0.39cm; margin-bottom: 0.11cm; line-height: 100%; orphans: 2; widows: 2; page-break-before: always">
<br/>
<br/>

</p>
<p align="justify" style="margin-top: 0.39cm; margin-bottom: 0.11cm; line-height: 100%; orphans: 2; widows: 2">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Figure
2: </font></font>
</p>
<p align="justify" style="margin-top: 0.39cm; margin-bottom: 0.11cm; line-height: 100%; orphans: 2; widows: 2">
<img src="2017_framescogsci_html_57f39f3d6790814f.png" name="Image2" align="left" width="672" height="286">
  <br clear="left"/>
</img>
<br/>
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2; page-break-before: always">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Figure
3:</font></font></p>
<img src="2017_framescogsci_html_f39672cb5c93cc24.png" name="Image3" align="left" width="364" height="432">
  <br clear="left"/>
</img>

<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2; page-break-before: always">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Figure
4: </font></font>
</p>
<img src="2017_framescogsci_html_57a05750394a466e.png" name="Image4" align="left" width="372" height="454" border="0"/>

<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2; page-break-before: always">
<font face="Latin Modern Roman"><font size="3" style="font-size: 12pt">Figure
5:</font></font></p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<img src="2017_framescogsci_html_404c2f09c035fa48.png" name="Image5" align="left" width="672" height="264" border="0"/>

<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
<p align="justify" style="margin-left: 0.32cm; text-indent: -0.32cm; margin-bottom: 0cm; line-height: 100%; orphans: 2; widows: 2">
<br/>

</p>
</body>
</html>